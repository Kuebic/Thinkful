{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Exploratory Data Analysis\n",
    "\n",
    "The goal of this notebook is to do some EDA and plotting of the data to get a better feel for it. In particular we will look at time series plots of certain features of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **A. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import job\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **B. BigQuery**\n",
    "\n",
    "**What is this query doing?**\n",
    "\n",
    "We look through the dataset and find every \"failure\" instance. We also randomly sample a roughly equal number of \"non failure\" instances, where we define a \"non failure\" in this scenario to mean not failing in the next 30 days (fail_this_month=0). Now for each of these \"failure\" and \"non failure\" instances, we extract a 30 day history. \n",
    "\n",
    "**Why?**\n",
    "\n",
    "Our goal is visualize time series of different SMART features. We want to accomplish two things:\n",
    " + What do the time series generally look like (are there interesting trends/patterns)?\n",
    " + How do the time series and/or average values for different features vary between \"failure\" and \"non failure\" instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_NAME_OF_TABLE = # Set this as `{project}.{dataset}.{table}`\n",
    "\n",
    "QUERY = \"\"\"\n",
    "WITH failures AS (\n",
    "SELECT \n",
    "  serial_number,\n",
    "  date as last_day\n",
    "FROM \n",
    "  {0}\n",
    "WHERE failure=1\n",
    "AND date < '2019-01-01'),\n",
    "\n",
    "non_failures AS (\n",
    "SELECT\n",
    "  serial_number,\n",
    "  date as last_day\n",
    "FROM \n",
    "  {0}\n",
    "WHERE fail_this_month=0\n",
    "AND date < '2019-01-01'\n",
    "AND MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(STRUCT(date,serial_number)))), \n",
    "    (SELECT COUNT(*) FROM {0})) < \n",
    "    (SELECT COUNT(*) FROM failures))\n",
    "\n",
    "SELECT \n",
    "  *,\n",
    "  30 - DATE_DIFF(last_day, date, day) as day_in_window\n",
    "FROM (\n",
    "SELECT\n",
    "  * \n",
    "FROM \n",
    "  non_failures \n",
    "JOIN {0}\n",
    "USING(serial_number)\n",
    "WHERE DATE_DIFF(last_day, date, day) < 30 AND DATE_DIFF(last_day, date, day) >= 0 \n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  *\n",
    "FROM \n",
    "  failures\n",
    "JOIN {0}\n",
    "USING(serial_number)\n",
    "WHERE DATE_DIFF(last_day, date, day) < 30)\n",
    "ORDER BY serial_number, date\n",
    "\"\"\".format(FULL_NAME_OF_TABLE)\n",
    "\n",
    "client = bigquery.Client()\n",
    "query_job = client.query(QUERY)\n",
    "\n",
    "frame = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **C. Visualizing Time Series**\n",
    "\n",
    "Now we have about 186,266 rows, corresponding to about 6000 different 30 day windows. Half of these windows (~3500) are meant to illustrate \"normal operating behavior\" while in the other half of these 30 day windows the drive will fail on the final day.\n",
    "\n",
    "The first thing we can look at is an average of these 30 day time series for particular features. From [a page](https://www.backblaze.com/blog/what-smart-stats-indicate-hard-drive-failures/) on the BackBlaze website we know that there are 5 features that the company looks at in order to predict drive failure: 5, 187, 188, 197, 198. We can start by looking at these five features (we ignore smart_188_raw for now since it is null for over 50% of the rows in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(features):\n",
    "    \"\"\"Make labels for x-axis\"\"\"\n",
    "    labels = [feat.split('_')[0].upper() + ' ' + feat.split('_')[1] \n",
    "              for feat in features]\n",
    "    return labels\n",
    "\n",
    "# From domain knowledge, we know that 5 features tend to be predictive of failure\n",
    "FEATURES_OF_INTEREST = ['smart_5_raw', 'smart_187_raw', 'smart_188_raw', \n",
    "                        'smart_197_raw', 'smart_198_raw'] \n",
    "LABELS = make_labels(FEATURES_OF_INTEREST)\n",
    "\n",
    "def plot_time_series(frame, sample=False, features=FEATURES_OF_INTEREST, labels=LABELS, save=False):\n",
    "    \"\"\"\n",
    "    Convenience function to plot some time series for some different features\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : DataFrame\n",
    "        A pandas DataFrame containing 30 day windows for healthy and infected drives\n",
    "        \n",
    "    sample : Bool\n",
    "        If true plot sample time series for single hard drives. Otherwise plot averages\n",
    "        for \"healthy\" and \"fail\" groups.\n",
    "        \n",
    "    features : List\n",
    "        List of strings indicating which features we'd like to plot\n",
    "        \n",
    "    labels : List\n",
    "        List of strings to be used as axis labels\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(features), 1, figsize=(10, 10))\n",
    "    \n",
    "    # Generate a random sample\n",
    "    if sample:\n",
    "        # Get all of the serial numbers that did and did not fail\n",
    "        no_fail_serial_numbers = frame[frame['fail_this_month']==0]['serial_number'].unique()\n",
    "        fail_serial_numbers = frame[frame['fail_this_month']==1]['serial_number'].unique()\n",
    "        # Get a random sample from each \n",
    "        no_fail_sample = frame[frame['serial_number'] == np.random.choice(no_fail_serial_numbers, 1)[0]]\n",
    "        fail_sample = frame[frame['serial_number'] == np.random.choice(fail_serial_numbers, 1)[0]]\n",
    "        \n",
    "        title = \"Sample Readings for Failed and Non-failed Drives for {} SMART Features\".format(len(features))\n",
    "    else:\n",
    "        title = \"Average Readings During 30-day Window for {} SMART Features\".format(len(features))  \n",
    "        \n",
    "    for ax, feat, label in zip(axes, features, labels):\n",
    "        if sample:\n",
    "            sns.lineplot(no_fail_sample['day_in_window'], no_fail_sample[feat], ax=ax)\n",
    "            sns.lineplot(fail_sample['day_in_window'], fail_sample[feat], ax=ax)\n",
    "        else:\n",
    "            sns.lineplot(x='day_in_window', y=feat, hue='fail_this_month', data=frame, ax=ax, legend=False)\n",
    "        \n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel(label)\n",
    "        \n",
    "    fig.legend(['No Fail', 'Fail'], loc='upper left', bbox_to_anchor = (0.1,-0.04,1,1))\n",
    "    fig.suptitle(title, va='bottom')\n",
    "    axes[-1].set_xlabel('Day in Window')  \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        if sample:\n",
    "            plt.savefig('sample_readings.png')\n",
    "        else:\n",
    "            plt.savefig('avg_readings.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does this plot tell us?**\n",
    "\n",
    "There's a lot of interesting conclusions that can be drawn from this plot: \n",
    " + there is a noticeable difference between the average readings for these 5 features for drives that did or did not fail. \n",
    " + the readings for SMART 197 and SMART 198 look nearly identical, this agrees with reporting by BackBlaze.\n",
    " + Non failed drives have higher average reading for SMART 188. This *does not* agree with reporting by BackBlazeâ€”these state: from the linked page \"when the RAW value for one of these five attributes is greater than zero, we have a reason to investigate\". Plot would seem to indicate the opposite for SMART 188"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples\n",
    "\n",
    "Time series look uninteresting for the most part (but this could be due to aggregation, we're only looking at averages). Lets look at individual samples to see if the time series still look uninteresting. This could help inform our modelling approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(frame, sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Rerun the two cells above to see different samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Features\n",
    "\n",
    "What happens if we do the same plots for some other features? Do we still see a noticeable difference between the two groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From domain knowledge, we know that these 5 features tend to be predictive of failure\n",
    "new_features = ['smart_12_raw', 'smart_189_raw', 'smart_190_raw', 'smart_193_raw', \\\n",
    "                        'smart_199_raw', 'smart_240_raw', 'smart_242_raw']\n",
    "new_labels = make_labels(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(frame, features=new_features, labels=new_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
