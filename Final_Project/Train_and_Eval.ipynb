{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Models\n",
    "\n",
    "As a baseline for comparison, we will use simple decision rules based on [domain knowledge](https://www.backblaze.com/blog/what-smart-stats-indicate-hard-drive-failures/)\n",
    "\n",
    "We will train models with no hyperparameter tuning just using default settings.  For each dataset, we will output several metrics for all models and baseline model.\n",
    "\n",
    "We chose the following models:\n",
    "- XGBoost\n",
    "- KNN\n",
    "- RandomForest\n",
    "- LinearSVC\n",
    "\n",
    "All datasets has been under_sampled so the 'majority' classification is roughly equal to the 'minority'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:16.898236Z",
     "iopub.status.busy": "2020-08-11T01:36:16.898236Z",
     "iopub.status.idle": "2020-08-11T01:36:19.558266Z",
     "shell.execute_reply": "2020-08-11T01:36:19.558266Z",
     "shell.execute_reply.started": "2020-08-11T01:36:16.898236Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import pickle\n",
    "\n",
    "HDD_PATH = os.path.join('datasets', 'drive_stats', '50_50')\n",
    "RESULTS_DIR = 'exploring_models/'\n",
    "\n",
    "FILENAME_LIST = ['fail_today', \n",
    "                 'fail_today_or_tomorrow', \n",
    "                 'fail_this_week',\n",
    "                 'fail_this_month']\n",
    "\n",
    "LABEL_DICT = {'fail_today': 'failure',\n",
    "              'fail_today_or_tomorrow': 'fail_today_or_tomorrow',\n",
    "              'fail_this_week': 'fail_this_week',\n",
    "              'fail_this_month': 'fail_this_month'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:19.562257Z",
     "iopub.status.busy": "2020-08-11T01:36:19.561259Z",
     "iopub.status.idle": "2020-08-11T01:36:19.591730Z",
     "shell.execute_reply": "2020-08-11T01:36:19.590181Z",
     "shell.execute_reply.started": "2020-08-11T01:36:19.562257Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_csv_as_frame(filename, hdd_path=HDD_PATH):\n",
    "    df = pd.read_csv(os.path.join(hdd_path, filename + '.csv'))\n",
    "    # Drop 'normalized' columns\n",
    "    cols_to_drop = [col for col in df.columns if 'normalized' in col]\n",
    "    df.drop(columns=cols_to_drop, inplace=True)\n",
    "    # Fill nulls\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    # Affirm dtypes of columns\n",
    "    columns = df.columns.tolist()\n",
    "    for col in columns:\n",
    "        if 'model' in col or 'serial_number' in col:\n",
    "            df[col] = df[col].astype('object')\n",
    "        elif 'date' in col or 'last_day' in col:\n",
    "            df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "        else:\n",
    "            df[col] = df[col].astype('int64')\n",
    "    return df\n",
    "\n",
    "def get_features(groups, cols, history=False):\n",
    "    aggs = ['last']\n",
    "    if history:\n",
    "        aggs += [np.mean, np.var, 'min', 'max']\n",
    "    features = groups[cols].agg(aggs)\n",
    "    # For some reason, nulls appear with history aggs, so impute them\n",
    "    for col in features:\n",
    "        features[col] = features[col].fillna(features[col].mode()[0])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:19.596677Z",
     "iopub.status.busy": "2020-08-11T01:36:19.596677Z",
     "iopub.status.idle": "2020-08-11T01:36:19.624601Z",
     "shell.execute_reply": "2020-08-11T01:36:19.621610Z",
     "shell.execute_reply.started": "2020-08-11T01:36:19.596677Z"
    }
   },
   "outputs": [],
   "source": [
    "def xgboost_train_and_predict(X_train, y_train, X_test):\n",
    "    bst = xgb.XGBClassifier()\n",
    "    bst.fit(X_train, y_train)\n",
    "    predictions = bst.predict(X_test)\n",
    "    return predictions, bst\n",
    "\n",
    "def knn_train_and_predict(X_train, y_train, X_test):\n",
    "    clf = make_pipeline(RobustScaler(),\n",
    "                       KNeighborsClassifier())\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    return predictions, clf\n",
    "\n",
    "def forest_train_and_predict(X_train, y_train, X_test):\n",
    "    forest = RandomForestClassifier(random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "    predictions = forest.predict(X_test)\n",
    "    return predictions, forest\n",
    "\n",
    "def lin_svc_train_and_predict(X_train, y_train, X_test):\n",
    "    clf = make_pipeline(RobustScaler(),\n",
    "                        LinearSVC(max_iter=80000))\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    return predictions, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:19.631584Z",
     "iopub.status.busy": "2020-08-11T01:36:19.628591Z",
     "iopub.status.idle": "2020-08-11T01:36:19.668484Z",
     "shell.execute_reply": "2020-08-11T01:36:19.665493Z",
     "shell.execute_reply.started": "2020-08-11T01:36:19.630586Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(preds, labels):\n",
    "    acc = metrics.accuracy_score(labels, preds)\n",
    "    recall = metrics.recall_score(labels, preds)\n",
    "    precision = metrics.precision_score(labels, preds)\n",
    "    F1 = metrics.f1_score(labels, preds)\n",
    "    auc = metrics.roc_auc_score(labels, preds)\n",
    "    confusion_matrix = metrics.confusion_matrix(labels, preds, labels=(0, 1))\n",
    "    return [acc, recall, precision, F1, auc] + list(confusion_matrix.ravel())\n",
    "\n",
    "def evaluate(preds, labels, table, end_time, model=None):\n",
    "    result = [table, model, end_time]\n",
    "    result += get_metrics(preds, labels)\n",
    "    return result\n",
    "\n",
    "def class_name(classifier, history):\n",
    "    if history:\n",
    "        model_name = '{}_history'.format(classifier)\n",
    "        file_name = '_{}_history.pickle.dat'.format(classifier)\n",
    "    else:\n",
    "        model_name = '{}'.format(classifier)\n",
    "        file_name = '_{}.pickle.dat'.format(classifier)\n",
    "    return model_name, file_name\n",
    "\n",
    "def train_eval_and_save(grouped,\n",
    "                        labels, \n",
    "                        cols_to_keep, \n",
    "                        table,\n",
    "                        history=False, \n",
    "                        results_dir=RESULTS_DIR,\n",
    "                        classifier='xgb'):\n",
    "    start_time = time.time()\n",
    "    features = get_features(grouped, cols_to_keep, history=history)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "                                                       test_size=0.2,\n",
    "                                                       random_state=123)\n",
    "    if classifier == 'xgb':\n",
    "        preds, model = xgboost_train_and_predict(X_train, y_train, X_test)\n",
    "    elif classifier == 'knn':\n",
    "        preds, model = knn_train_and_predict(X_train, y_train, X_test)\n",
    "    elif classifier == 'forest':\n",
    "        preds, model = forest_train_and_predict(X_train, y_train, X_test)\n",
    "    elif classifier == 'lin_svc':\n",
    "        preds, model = lin_svc_train_and_predict(X_train, y_train, X_test)\n",
    "    else:\n",
    "        print ('No Classifier: type either xgb, knn, forest, or lin_svc')\n",
    "    end_time = time.time() - start_time\n",
    "    print('Time taken: {}s'.format(end_time))\n",
    "    model_name, file_name = class_name(classifier, history)\n",
    "    result = evaluate(preds, y_test, table, end_time, model_name)\n",
    "    # Save the model\n",
    "    pickle.dump(model, open(results_dir + table + file_name, 'wb'))\n",
    "    return result, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:19.673471Z",
     "iopub.status.busy": "2020-08-11T01:36:19.671477Z",
     "iopub.status.idle": "2020-08-11T01:36:19.699401Z",
     "shell.execute_reply": "2020-08-11T01:36:19.698405Z",
     "shell.execute_reply.started": "2020-08-11T01:36:19.672473Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULTS_DIR):\n",
    "    os.makedirs(RESULTS_DIR)\n",
    "    \n",
    "BASELINE_FEATURES = ['smart_5_raw', 'smart_187_raw',\n",
    "                    'smart_188_raw', 'smart_197_raw',\n",
    "                    'smart_198_raw']\n",
    "\n",
    "CLASSIFIER_LIST = ['xgb', 'knn', 'forest', 'lin_svc']\n",
    "\n",
    "def run_tests(filename_list=FILENAME_LIST, \n",
    "              label_dict=LABEL_DICT, \n",
    "              class_list=CLASSIFIER_LIST,\n",
    "              baseline_features=BASELINE_FEATURES):\n",
    "    results = []\n",
    "    for table in filename_list:\n",
    "        print(\"{:=^80}\".format(\" Training on {} \".format(table)))\n",
    "        dataset = get_csv_as_frame(table)\n",
    "        cols_to_keep = [col for col in dataset.columns if 'smart' in col]\n",
    "        # Groupby will get 10 day windows\n",
    "        grouped = dataset.groupby(['serial_number', 'last_day'])\n",
    "        # Label should always be what the last day in the windows is\n",
    "        labels = grouped[label_dict[table]].agg('last')\n",
    "        for classifier in class_list:\n",
    "            print(\"{:=^80}\".format(\" Evaluating {} with History \".format(classifier)))\n",
    "            try:\n",
    "                result_history, _, _ = train_eval_and_save(grouped,\n",
    "                                                           labels,\n",
    "                                                           cols_to_keep,\n",
    "                                                           table,\n",
    "                                                           history=True,\n",
    "                                                           classifier=classifier)\n",
    "                results.append(result_history)\n",
    "            except ValueError:\n",
    "                print('Stupid things happened to {} with history'.format(classifier))\n",
    "            print(\"{:=^80}\".format(\" Evaluating {} without History \".format(classifier)))\n",
    "            start_time = time.time()\n",
    "            result, X_test, y_test = train_eval_and_save(grouped,\n",
    "                                                         labels,\n",
    "                                                         cols_to_keep,\n",
    "                                                         table,\n",
    "                                                         history=False,\n",
    "                                                         classifier=classifier)\n",
    "            results.append(result)\n",
    "        print('{:-^80}'.format(\" Evaluating Baseline \"))\n",
    "        preds_manual = np.any(\n",
    "            X_test[baseline_features].values > 0, axis=1).astype(int)\n",
    "        results.append(evaluate(preds_manual, y_test, table, 'baseline'))\n",
    "        print(\"\\n \\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T01:36:19.701397Z",
     "iopub.status.busy": "2020-08-11T01:36:19.701397Z",
     "iopub.status.idle": "2020-08-11T05:27:04.459688Z",
     "shell.execute_reply": "2020-08-11T05:27:04.458692Z",
     "shell.execute_reply.started": "2020-08-11T01:36:19.701397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Training on fail_today ============================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "Time taken: 4.658549785614014s\n",
      "======================== Evaluating xgb without History ========================\n",
      "Time taken: 1.1000597476959229s\n",
      "========================= Evaluating knn with History ==========================\n",
      "Time taken: 1.9378204345703125s\n",
      "======================== Evaluating knn without History ========================\n",
      "Time taken: 0.47672557830810547s\n",
      "======================== Evaluating forest with History ========================\n",
      "Time taken: 3.296919345855713s\n",
      "====================== Evaluating forest without History =======================\n",
      "Time taken: 1.3875246047973633s\n",
      "======================= Evaluating lin_svc with History ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 118.92120313644409s\n",
      "====================== Evaluating lin_svc without History ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 32.525153398513794s\n",
      "----------------------------- Evaluating Baseline ------------------------------\n",
      "\n",
      " \n",
      "\n",
      "====================== Training on fail_today_or_tomorrow ======================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "Time taken: 6.6488518714904785s\n",
      "======================== Evaluating xgb without History ========================\n",
      "Time taken: 1.8824799060821533s\n",
      "========================= Evaluating knn with History ==========================\n",
      "Time taken: 5.310841798782349s\n",
      "======================== Evaluating knn without History ========================\n",
      "Time taken: 1.2899343967437744s\n",
      "======================== Evaluating forest with History ========================\n",
      "Time taken: 7.159361124038696s\n",
      "====================== Evaluating forest without History =======================\n",
      "Time taken: 2.7207283973693848s\n",
      "======================= Evaluating lin_svc with History ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 264.8507146835327s\n",
      "====================== Evaluating lin_svc without History ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 99.57688426971436s\n",
      "----------------------------- Evaluating Baseline ------------------------------\n",
      "\n",
      " \n",
      "\n",
      "========================== Training on fail_this_week ==========================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "Time taken: 23.388913869857788s\n",
      "======================== Evaluating xgb without History ========================\n",
      "Time taken: 6.452430963516235s\n",
      "========================= Evaluating knn with History ==========================\n",
      "Time taken: 40.6409957408905s\n",
      "======================== Evaluating knn without History ========================\n",
      "Time taken: 13.59852385520935s\n",
      "======================== Evaluating forest with History ========================\n",
      "Time taken: 25.363605976104736s\n",
      "====================== Evaluating forest without History =======================\n",
      "Time taken: 10.621796369552612s\n",
      "======================= Evaluating lin_svc with History ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1218.452787399292s\n",
      "====================== Evaluating lin_svc without History ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 645.3991339206696s\n",
      "----------------------------- Evaluating Baseline ------------------------------\n",
      "\n",
      " \n",
      "\n",
      "========================= Training on fail_this_month ==========================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "Time taken: 99.89101648330688s\n",
      "======================== Evaluating xgb without History ========================\n",
      "Time taken: 23.835524797439575s\n",
      "========================= Evaluating knn with History ==========================\n",
      "Time taken: 576.5933685302734s\n",
      "======================== Evaluating knn without History ========================\n",
      "Time taken: 198.99973702430725s\n",
      "======================== Evaluating forest with History ========================\n",
      "Time taken: 140.58676958084106s\n",
      "====================== Evaluating forest without History =======================\n",
      "Time taken: 57.53584814071655s\n",
      "======================= Evaluating lin_svc with History ========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 6336.98339676857s\n",
      "====================== Evaluating lin_svc without History ======================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenei\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3794.034133195877s\n",
      "----------------------------- Evaluating Baseline ------------------------------\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:27:04.461684Z",
     "iopub.status.busy": "2020-08-11T05:27:04.461684Z",
     "iopub.status.idle": "2020-08-11T05:27:04.481629Z",
     "shell.execute_reply": "2020-08-11T05:27:04.480632Z",
     "shell.execute_reply.started": "2020-08-11T05:27:04.461684Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_cols = ['Dataset', 'model', 'time',\n",
    "             'accuracy', 'recall',  \n",
    "             'precision', 'F1', \n",
    "             'auc', 'TN', 'FP', 'FN', 'TP']\n",
    "\n",
    "results_frame = pd.DataFrame(results, columns=eval_cols)\n",
    "\n",
    "results_frame.to_csv(RESULTS_DIR + 'full_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Overfitting\n",
    "\n",
    "I want to make sure models are not overfitting, especially the forest model with over 90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:27:04.483626Z",
     "iopub.status.busy": "2020-08-11T05:27:04.482626Z",
     "iopub.status.idle": "2020-08-11T05:27:04.535486Z",
     "shell.execute_reply": "2020-08-11T05:27:04.534490Z",
     "shell.execute_reply.started": "2020-08-11T05:27:04.483626Z"
    }
   },
   "outputs": [],
   "source": [
    "# CLASSIFIER_LIST = ['xgb', 'forest']\n",
    "\n",
    "def test_overfitting(filename_list=FILENAME_LIST, \n",
    "                     label_dict=LABEL_DICT, \n",
    "                     class_list=CLASSIFIER_LIST,\n",
    "                     baseline_features=BASELINE_FEATURES):\n",
    "    model_folder = os.path.join('exploring_models')\n",
    "    results = []\n",
    "    for table in filename_list:\n",
    "        print(\"{:=^80}\".format(\" Checking on {} \".format(table)))\n",
    "        # Making Training and Test sets\n",
    "        dataset = get_csv_as_frame(table)\n",
    "        cols_to_keep = [col for col in dataset.columns if 'smart' in col]\n",
    "        # Groupby will get 10 day windows\n",
    "        grouped = dataset.groupby(['serial_number', 'last_day'])\n",
    "        # Label should always be what the last day in the windows is\n",
    "        labels = grouped[label_dict[table]].agg('last')\n",
    "        for classifier in class_list:\n",
    "            print(\"{:=^80}\".format(\" Evaluating {} with History \".format(classifier)))\n",
    "            features = get_features(grouped, cols_to_keep, history=True)\n",
    "            model_name, file_name = class_name(classifier, history=True)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                                labels,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=123)\n",
    "            loaded_model = pickle.load(open(\n",
    "                model_folder + '/{}{}'.format(table, file_name), 'rb'))\n",
    "            pred_train = loaded_model.predict(X_train)\n",
    "            pred_test = loaded_model.predict(X_test)\n",
    "            \n",
    "            result_train = evaluate(pred_train, y_train, table, end_time='train', model=model_name)\n",
    "            results.append(result_train)\n",
    "            result_test = evaluate(pred_test, y_test, table, end_time='test', model=model_name)\n",
    "            results.append(result_test)\n",
    "            \n",
    "            print(\"{:=^80}\".format(\" Evaluating {} without History \".format(classifier)))\n",
    "            features = get_features(grouped, cols_to_keep, history=False)\n",
    "            model_name, file_name = class_name(classifier, history=False)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                                labels,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=123)\n",
    "            loaded_model = pickle.load(open(\n",
    "                model_folder + '/{}{}'.format(table, file_name), 'rb'))\n",
    "            pred_train = loaded_model.predict(X_train)\n",
    "            pred_test = loaded_model.predict(X_test)\n",
    "            \n",
    "            result_train = evaluate(pred_train, y_train, table, end_time='train', model=model_name)\n",
    "            results.append(result_train)\n",
    "            result_test = evaluate(pred_test, y_test, table, end_time='test', model=model_name)\n",
    "            results.append(result_test)\n",
    "        print(\"\\n \\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:27:04.540473Z",
     "iopub.status.busy": "2020-08-11T05:27:04.539475Z",
     "iopub.status.idle": "2020-08-11T06:25:57.712906Z",
     "shell.execute_reply": "2020-08-11T06:25:57.711908Z",
     "shell.execute_reply.started": "2020-08-11T05:27:04.540473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Checking on fail_today ============================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "======================== Evaluating xgb without History ========================\n",
      "========================= Evaluating knn with History ==========================\n",
      "======================== Evaluating knn without History ========================\n",
      "======================== Evaluating forest with History ========================\n",
      "====================== Evaluating forest without History =======================\n",
      "======================= Evaluating lin_svc with History ========================\n",
      "====================== Evaluating lin_svc without History ======================\n",
      "\n",
      " \n",
      "\n",
      "====================== Checking on fail_today_or_tomorrow ======================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "======================== Evaluating xgb without History ========================\n",
      "========================= Evaluating knn with History ==========================\n",
      "======================== Evaluating knn without History ========================\n",
      "======================== Evaluating forest with History ========================\n",
      "====================== Evaluating forest without History =======================\n",
      "======================= Evaluating lin_svc with History ========================\n",
      "====================== Evaluating lin_svc without History ======================\n",
      "\n",
      " \n",
      "\n",
      "========================== Checking on fail_this_week ==========================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "======================== Evaluating xgb without History ========================\n",
      "========================= Evaluating knn with History ==========================\n",
      "======================== Evaluating knn without History ========================\n",
      "======================== Evaluating forest with History ========================\n",
      "====================== Evaluating forest without History =======================\n",
      "======================= Evaluating lin_svc with History ========================\n",
      "====================== Evaluating lin_svc without History ======================\n",
      "\n",
      " \n",
      "\n",
      "========================= Checking on fail_this_month ==========================\n",
      "========================= Evaluating xgb with History ==========================\n",
      "======================== Evaluating xgb without History ========================\n",
      "========================= Evaluating knn with History ==========================\n",
      "======================== Evaluating knn without History ========================\n",
      "======================== Evaluating forest with History ========================\n",
      "====================== Evaluating forest without History =======================\n",
      "======================= Evaluating lin_svc with History ========================\n",
      "====================== Evaluating lin_svc without History ======================\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = test_overfitting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T06:25:57.714901Z",
     "iopub.status.busy": "2020-08-11T06:25:57.714901Z",
     "iopub.status.idle": "2020-08-11T06:25:57.734362Z",
     "shell.execute_reply": "2020-08-11T06:25:57.733366Z",
     "shell.execute_reply.started": "2020-08-11T06:25:57.714901Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_cols = ['Dataset', 'model', 'type',\n",
    "             'accuracy', 'recall',  \n",
    "             'precision', 'F1', \n",
    "             'auc', 'TN', 'FP', 'FN', 'TP']\n",
    "\n",
    "results_frame = pd.DataFrame(results, columns=eval_cols)\n",
    "\n",
    "results_frame.to_csv(RESULTS_DIR + 'overfitting_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
